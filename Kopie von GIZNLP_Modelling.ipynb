{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEgmrqv0_wgD"
   },
   "source": [
    "# GIZ NLP Agricultural Keyword Spotter\n",
    "\n",
    "File name: GIZNLP_Modelling.ipynb\n",
    "\n",
    "Author: kogni7\n",
    "\n",
    "Date: October/November 2020\n",
    "\n",
    "## Contents\n",
    "* 1 Preparation\n",
    "  * 1.1 Libraries and Seed\n",
    "  * 1.2 Variables\n",
    "* 2 Data\n",
    "* 3 Model\n",
    "* 4 Train Algorithm\n",
    "* 5 Submission\n",
    "  * 5.1 Training\n",
    "  * 5.2 Prediction\n",
    "  * 5.3 Saving\n",
    "\n",
    "At first, run the preprocessing notebook!\n",
    "\n",
    "This notebook uses only the data sets provided by ZINDI. These data sets contain wav-files which are vocal utterances in English and Luganda. The (processed) utterances are the only used features in this notebook.\n",
    "\n",
    "The file system for this project is:\n",
    "\n",
    "- GIZNLP (root)\n",
    "  - GIZNLP_Preprocessing.ipynb\n",
    "  - GIZNLP_Modelling.ipynb (this notebook)\n",
    "  - Data\n",
    "      - audio_files\n",
    "      - latest_keywords\n",
    "      - nlp_keywords\n",
    "      - Train.csv\n",
    "      - SampleSubmission.csv\n",
    "  - Preprocessed_Data (will be created during the run of the preprocessing notebook)\n",
    "  - Submission\n",
    "      - 1 - x: Submission directories, named by the version number\n",
    "          - checkpoint_model.h5 (saved keras model)\n",
    "          - model.h5 (saved keras model)\n",
    "          - submission.csv\n",
    "\n",
    "This jupyter notebook runs in Google Colab without special configuration (and with the automatically loaded packages).\n",
    "\n",
    "The GPU is enabled for hardware acceleration. The results are probably not exactly reproducible, but the differences should be small.\n",
    "\n",
    "This notebook uses some basic ideas from the starter notebook.\n",
    "\n",
    "The idea of the notebook is a deep learning based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HinBZk5_wgE"
   },
   "source": [
    "## 1. Preparation\n",
    "### 1.1 Libraries and Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2218,
     "status": "ok",
     "timestamp": 1606585019648,
     "user": {
      "displayName": "Andreas Schmitt",
      "photoUrl": "",
      "userId": "08919543814682882005"
     },
     "user_tz": -60
    },
    "id": "0Uaf_Ltn_wgE"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Seeds\n",
    "import random\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "np.random.seed(SEED + 1)\n",
    "random.seed(SEED + 2)\n",
    "\n",
    "tf.random.set_seed(SEED + 3)\n",
    "\n",
    "# Working with CSV\n",
    "import pandas as pd\n",
    "\n",
    "# Further imports\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning\n",
    "from keras.models import Model\n",
    "from keras.layers import AveragePooling2D, BatchNormalization, Conv2D, Dense, Dropout, GlobalAveragePooling2D, Input, MaxPooling2D, ReLU, SpatialDropout2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7Trr_F-_wgF"
   },
   "source": [
    "### 1.2 Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21063,
     "status": "ok",
     "timestamp": 1606585038505,
     "user": {
      "displayName": "Andreas Schmitt",
      "photoUrl": "",
      "userId": "08919543814682882005"
     },
     "user_tz": -60
    },
    "id": "M9duUVPr_wgF",
    "outputId": "c72c690b-4214-450c-bc56-968d9fed43c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Colab Notebooks/GIZNLP\n"
     ]
    }
   ],
   "source": [
    "# Time \n",
    "start_time = time.time()\n",
    "\n",
    "# The Version\n",
    "VERSION = 'test_c'\n",
    "\n",
    "# for use in Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Working Directory\n",
    "WD = os.getcwd() + \"/drive/My Drive/Colab Notebooks/GIZNLP\"\n",
    "print(WD)\n",
    "\n",
    "# Classes\n",
    "CLASSES = 193"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a52GiTF0_wgG"
   },
   "source": [
    "## 2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 27960,
     "status": "ok",
     "timestamp": 1606585045407,
     "user": {
      "displayName": "Andreas Schmitt",
      "photoUrl": "",
      "userId": "08919543814682882005"
     },
     "user_tz": -60
    },
    "id": "uA-x-GMg_wgG"
   },
   "outputs": [],
   "source": [
    "# The preprocessed data\n",
    "with open(WD + '/Preprocessed_Data/X.dat', 'rb') as file:\n",
    "    X = pickle.load(file)\n",
    "\n",
    "with open(WD + '/Preprocessed_Data/y.dat', 'rb') as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "with open(WD + '/Preprocessed_Data/X_val.dat', 'rb') as file:\n",
    "    X_val = pickle.load(file)\n",
    "\n",
    "with open(WD + '/Preprocessed_Data/y_val.dat', 'rb') as file:\n",
    "    y_val = pickle.load(file)\n",
    "\n",
    "with open(WD + '/Preprocessed_Data/X_test.dat', 'rb') as file:\n",
    "    X_test = pickle.load(file)\n",
    "\n",
    "# The original sample submission\n",
    "sample_submission = pd.read_csv(WD + '/Data/SampleSubmission.csv')\n",
    "sample_submission_fn = sample_submission.fn\n",
    "sample_submission_index = sample_submission.index\n",
    "sample_submission_columns = sample_submission.columns\n",
    "del sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmnacwuA_wgN"
   },
   "source": [
    "## 3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 27962,
     "status": "ok",
     "timestamp": 1606585045413,
     "user": {
      "displayName": "Andreas Schmitt",
      "photoUrl": "",
      "userId": "08919543814682882005"
     },
     "user_tz": -60
    },
    "id": "fn15Fs_1_wgN",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_model(parameters):\n",
    "    \"\"\"\n",
    "    The model using deep learning.\n",
    "    \"\"\"\n",
    "\n",
    "    input = Input(shape=(None, None, 1))\n",
    "\n",
    "    layer = input\n",
    "\n",
    "    for letter in parameters[\"Structure\"]:\n",
    "\n",
    "        # Conv\n",
    "        if letter == \"C\":\n",
    "            layer = Conv2D(parameters[\"filters\"][0], parameters[\"kernel_size\"][0],\n",
    "                           kernel_constraint=parameters[\"Conv_constraint\"],\n",
    "                           bias_constraint=parameters[\"Conv_constraint\"],\n",
    "                           data_format='channels_last')(layer)\n",
    "            parameters[\"filters\"].pop(0)\n",
    "            parameters[\"kernel_size\"].pop(0)\n",
    "\n",
    "        # Dense\n",
    "        if letter == \"D\":\n",
    "            layer = Dense(parameters[\"Dense_units\"][0],\n",
    "                          kernel_constraint=parameters[\"Dense_constraint\"],\n",
    "                          bias_constraint=parameters[\"Dense_constraint\"])(layer)\n",
    "            parameters[\"Dense_units\"].pop(0)\n",
    "\n",
    "        # MaxPooling\n",
    "        if letter == \"M\":\n",
    "            layer = MaxPooling2D(pool_size=parameters[\"pool_size\"][0])(layer)\n",
    "            parameters[\"pool_size\"].pop(0)\n",
    "\n",
    "        # AveragePooling\n",
    "        if letter == \"A\":\n",
    "            layer = AveragePooling2D(pool_size=parameters[\"pool_size\"][0])(layer)\n",
    "            parameters[\"pool_size\"].pop(0)\n",
    "\n",
    "        # GlobalAveragePooling\n",
    "        if letter == \"G\": layer = GlobalAveragePooling2D()(layer)\n",
    "\n",
    "        # ReLU\n",
    "        if letter == \"R\": layer = ReLU()(layer)\n",
    "\n",
    "        # Dropout\n",
    "        if letter == \"O\":\n",
    "            layer = Dropout(parameters[\"rate\"][0], seed=SEED)(layer)  \n",
    "            parameters[\"rate\"].pop(0)\n",
    "\n",
    "        # SpatialDropout\n",
    "        if letter == \"S\":\n",
    "            layer = SpatialDropout2D(parameters[\"spatial_rate\"][0])(layer)\n",
    "            parameters[\"spatial_rate\"].pop(0)\n",
    "\n",
    "        # BatchNormalization\n",
    "        if letter == \"N\": layer = BatchNormalization()(layer)\n",
    "\n",
    "    # OUPUT\n",
    "    output = Dense(CLASSES, activation='sigmoid')(layer)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "\n",
    "    # Model run\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=parameters['lr']))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtTfqlVK_wgN"
   },
   "source": [
    "## 4 Train Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 27959,
     "status": "ok",
     "timestamp": 1606585045414,
     "user": {
      "displayName": "Andreas Schmitt",
      "photoUrl": "",
      "userId": "08919543814682882005"
     },
     "user_tz": -60
    },
    "id": "laa9nfGz_wgN"
   },
   "outputs": [],
   "source": [
    "def training(X, y, X_val, y_val, parameters):\n",
    "    \"\"\"\n",
    "    This function is the procedure of a training, i.e. 80% of data for training and 20% for validation.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Training is starting...\")\n",
    "\n",
    "    # Model\n",
    "    print(\"\\nModel building...\")\n",
    "    model = get_model(parameters)\n",
    "    model.summary()\n",
    "\n",
    "    # Modelcheckpoint\n",
    "    modelcheckpoint = ModelCheckpoint(filepath=WD + '/Submission/' + str(VERSION) + '/checkpoint_model.h5',\n",
    "                                      save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "    # Early Stopping\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n",
    "\n",
    "    # Fit\n",
    "    print(\"\\nFitting...\")\n",
    "    model_fit=model.fit(X, y,\n",
    "                        batch_size=parameters[\"batch_size\"],\n",
    "                        epochs=parameters[\"epochs\"],\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[modelcheckpoint, earlystopping])\n",
    "\n",
    "    model.load_weights(WD + '/Submission/' + str(VERSION) + '/checkpoint_model.h5')\n",
    "\n",
    "    # Minima\n",
    "    val_loss = np.min(model_fit.history['val_loss'])\n",
    "    epoch = model_fit.history['val_loss'].index(val_loss)\n",
    "    train_loss = model_fit.history['loss'][epoch]\n",
    "\n",
    "    print(\"Best epoch: {}; TRAIN loss: {:.4f}, VAL loss: {:.4f}\".format(epoch, train_loss, val_loss))\n",
    "\n",
    "    # Plot\n",
    "    plot_df = pd.DataFrame(model_fit.history)\n",
    "    plot_df.loc[:, ['loss', 'val_loss']].plot()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_eo4WbN_wgO"
   },
   "source": [
    "## 5 Submission\n",
    "### 5.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 962078,
     "status": "ok",
     "timestamp": 1606585979536,
     "user": {
      "displayName": "Andreas Schmitt",
      "photoUrl": "",
      "userId": "08919543814682882005"
     },
     "user_tz": -60
    },
    "id": "p7pS2Vk2_wgO",
    "outputId": "45b4f879-0806-4684-95ee-8790a4963cc7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is starting...\n",
      "\n",
      "Model building...\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 1)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, None, None, 64)    1664      \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d (SpatialDr (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 128)   204928    \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_1 (Spatial (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 256)   819456    \n",
      "_________________________________________________________________\n",
      "spatial_dropout2d_2 (Spatial (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2000)              514000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2000)              8000      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 193)               96693     \n",
      "=================================================================\n",
      "Total params: 4,154,033\n",
      "Trainable params: 4,146,137\n",
      "Non-trainable params: 7,896\n",
      "_________________________________________________________________\n",
      "\n",
      "Fitting...\n",
      "Epoch 1/100\n",
      "76/76 [==============================] - 11s 141ms/step - loss: 5.9192 - val_loss: 9.1810\n",
      "Epoch 2/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 5.2928 - val_loss: 5.7174\n",
      "Epoch 3/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 5.0944 - val_loss: 5.0412\n",
      "Epoch 4/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 5.0006 - val_loss: 5.1113\n",
      "Epoch 5/100\n",
      "76/76 [==============================] - 10s 130ms/step - loss: 4.9003 - val_loss: 5.1589\n",
      "Epoch 6/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 4.7810 - val_loss: 4.9688\n",
      "Epoch 7/100\n",
      "76/76 [==============================] - 10s 135ms/step - loss: 4.6694 - val_loss: 4.8505\n",
      "Epoch 8/100\n",
      "76/76 [==============================] - 10s 135ms/step - loss: 4.5610 - val_loss: 4.7136\n",
      "Epoch 9/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 4.5054 - val_loss: 4.6766\n",
      "Epoch 10/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 4.3918 - val_loss: 4.9468\n",
      "Epoch 11/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 4.3121 - val_loss: 4.6059\n",
      "Epoch 12/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 4.2104 - val_loss: 4.4035\n",
      "Epoch 13/100\n",
      "76/76 [==============================] - 10s 130ms/step - loss: 4.1153 - val_loss: 4.4511\n",
      "Epoch 14/100\n",
      "76/76 [==============================] - 10s 130ms/step - loss: 4.0253 - val_loss: 4.4839\n",
      "Epoch 15/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 3.9052 - val_loss: 4.1260\n",
      "Epoch 16/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 3.8806 - val_loss: 4.0922\n",
      "Epoch 17/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 3.7370 - val_loss: 3.9774\n",
      "Epoch 18/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 3.6839 - val_loss: 3.8405\n",
      "Epoch 19/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 3.5924 - val_loss: 3.8423\n",
      "Epoch 20/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 3.5270 - val_loss: 3.7950\n",
      "Epoch 21/100\n",
      "76/76 [==============================] - 10s 131ms/step - loss: 3.4368 - val_loss: 3.6266\n",
      "Epoch 22/100\n",
      "76/76 [==============================] - 10s 131ms/step - loss: 3.3529 - val_loss: 3.5542\n",
      "Epoch 23/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 3.2952 - val_loss: 3.5097\n",
      "Epoch 24/100\n",
      "76/76 [==============================] - 10s 130ms/step - loss: 3.2211 - val_loss: 3.5587\n",
      "Epoch 25/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 3.1343 - val_loss: 3.3492\n",
      "Epoch 26/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 3.0250 - val_loss: 3.1494\n",
      "Epoch 27/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 2.9562 - val_loss: 3.1218\n",
      "Epoch 28/100\n",
      "76/76 [==============================] - 10s 130ms/step - loss: 2.8719 - val_loss: 3.2304\n",
      "Epoch 29/100\n",
      "76/76 [==============================] - 10s 130ms/step - loss: 2.8080 - val_loss: 3.7406\n",
      "Epoch 30/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 2.7859 - val_loss: 3.0084\n",
      "Epoch 31/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 2.6380 - val_loss: 3.1249\n",
      "Epoch 32/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 2.5912 - val_loss: 3.0251\n",
      "Epoch 33/100\n",
      "76/76 [==============================] - 10s 130ms/step - loss: 2.4922 - val_loss: 3.0385\n",
      "Epoch 34/100\n",
      "76/76 [==============================] - 10s 135ms/step - loss: 2.3854 - val_loss: 2.7488\n",
      "Epoch 35/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 2.3326 - val_loss: 2.6698\n",
      "Epoch 36/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 2.2697 - val_loss: 2.6352\n",
      "Epoch 37/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 2.2128 - val_loss: 2.4696\n",
      "Epoch 38/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 2.1428 - val_loss: 2.5248\n",
      "Epoch 39/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 2.0454 - val_loss: 2.3949\n",
      "Epoch 40/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 2.0060 - val_loss: 2.2608\n",
      "Epoch 41/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.9402 - val_loss: 2.5617\n",
      "Epoch 42/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.8547 - val_loss: 2.4431\n",
      "Epoch 43/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.8191 - val_loss: 2.5145\n",
      "Epoch 44/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.7585 - val_loss: 2.2859\n",
      "Epoch 45/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 1.7216 - val_loss: 1.8499\n",
      "Epoch 46/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.6728 - val_loss: 1.9049\n",
      "Epoch 47/100\n",
      "76/76 [==============================] - 10s 128ms/step - loss: 1.6294 - val_loss: 2.0244\n",
      "Epoch 48/100\n",
      "76/76 [==============================] - 10s 128ms/step - loss: 1.5196 - val_loss: 1.9967\n",
      "Epoch 49/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.5367 - val_loss: 1.9630\n",
      "Epoch 50/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.4890 - val_loss: 1.8967\n",
      "Epoch 51/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.4573 - val_loss: 1.9315\n",
      "Epoch 52/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.3801 - val_loss: 1.8761\n",
      "Epoch 53/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 1.3696 - val_loss: 1.8335\n",
      "Epoch 54/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.3348 - val_loss: 1.9597\n",
      "Epoch 55/100\n",
      "76/76 [==============================] - 10s 128ms/step - loss: 1.2558 - val_loss: 1.8387\n",
      "Epoch 56/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 1.2297 - val_loss: 1.7183\n",
      "Epoch 57/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.2340 - val_loss: 1.8091\n",
      "Epoch 58/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 1.2339 - val_loss: 1.7056\n",
      "Epoch 59/100\n",
      "76/76 [==============================] - 10s 130ms/step - loss: 1.1840 - val_loss: 1.6527\n",
      "Epoch 60/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.1026 - val_loss: 1.6748\n",
      "Epoch 61/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.0859 - val_loss: 1.7176\n",
      "Epoch 62/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 1.1164 - val_loss: 1.6377\n",
      "Epoch 63/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 1.0687 - val_loss: 1.6056\n",
      "Epoch 64/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.0326 - val_loss: 1.6210\n",
      "Epoch 65/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 1.0143 - val_loss: 1.6152\n",
      "Epoch 66/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 1.0073 - val_loss: 1.5918\n",
      "Epoch 67/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.9969 - val_loss: 1.7403\n",
      "Epoch 68/100\n",
      "76/76 [==============================] - 10s 128ms/step - loss: 0.9627 - val_loss: 1.6962\n",
      "Epoch 69/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 0.9211 - val_loss: 1.5886\n",
      "Epoch 70/100\n",
      "76/76 [==============================] - 10s 130ms/step - loss: 0.9211 - val_loss: 1.5797\n",
      "Epoch 71/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.8749 - val_loss: 1.5903\n",
      "Epoch 72/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.8793 - val_loss: 1.6089\n",
      "Epoch 73/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 0.8302 - val_loss: 1.5498\n",
      "Epoch 74/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.8426 - val_loss: 1.5856\n",
      "Epoch 75/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.8383 - val_loss: 1.7827\n",
      "Epoch 76/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 0.8255 - val_loss: 1.5202\n",
      "Epoch 77/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 0.8292 - val_loss: 1.4915\n",
      "Epoch 78/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 0.7450 - val_loss: 1.3940\n",
      "Epoch 79/100\n",
      "76/76 [==============================] - 10s 128ms/step - loss: 0.8033 - val_loss: 1.5116\n",
      "Epoch 80/100\n",
      "76/76 [==============================] - 10s 133ms/step - loss: 0.7700 - val_loss: 1.3875\n",
      "Epoch 81/100\n",
      "76/76 [==============================] - 10s 134ms/step - loss: 0.7598 - val_loss: 1.3755\n",
      "Epoch 82/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.7041 - val_loss: 1.5426\n",
      "Epoch 83/100\n",
      "76/76 [==============================] - 10s 128ms/step - loss: 0.7404 - val_loss: 1.5115\n",
      "Epoch 84/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.7264 - val_loss: 1.3907\n",
      "Epoch 85/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.6751 - val_loss: 1.4397\n",
      "Epoch 86/100\n",
      "76/76 [==============================] - 10s 128ms/step - loss: 0.7034 - val_loss: 1.4199\n",
      "Epoch 87/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.6506 - val_loss: 1.4357\n",
      "Epoch 88/100\n",
      "76/76 [==============================] - 10s 128ms/step - loss: 0.6947 - val_loss: 1.4386\n",
      "Epoch 89/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.6435 - val_loss: 1.4103\n",
      "Epoch 90/100\n",
      "76/76 [==============================] - 10s 129ms/step - loss: 0.6509 - val_loss: 1.4642\n",
      "Epoch 91/100\n",
      "76/76 [==============================] - 10s 130ms/step - loss: 0.6370 - val_loss: 1.3807\n",
      "Best epoch: 80; TRAIN loss: 0.7598, VAL loss: 1.3755\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = {}\n",
    "\n",
    "\"\"\"\n",
    "Define the net structure with the following notation:\n",
    "1   Conv2D                  C\n",
    "2   Dense                   D\n",
    "3   MaxPooling              M\n",
    "4   AveragePooling          A\n",
    "5   GlobalAveragePooling    G\n",
    "6   ReLU                    R\n",
    "7   Dropout                 O\n",
    "8   SpatialDropout          S\n",
    "9   BatchNormalization      N\n",
    "\"\"\"\n",
    "\n",
    "parameters[\"Structure\"] = 'C' + 'S' + 'N' + 'R' + 'A' + \\\n",
    "                          'C' + 'S' + 'N' + 'R' + 'A' + \\\n",
    "                          'C' + 'S' + 'N' + 'R' + 'G' + \\\n",
    "                          'D' + 'O' + 'N' + 'R' + \\\n",
    "                          'D' + 'O' + 'N' + 'R' + \\\n",
    "                          'D' + 'O' + 'N' + 'R'\n",
    "\n",
    "# Conv2D\n",
    "parameters[\"filters\"] = [64, 128, 256]\n",
    "parameters[\"kernel_size\"] = [(5, 5), (5, 5), (5, 5)]\n",
    "parameters[\"Conv_constraint\"] = None\n",
    "\n",
    "# Pooling\n",
    "parameters[\"pool_size\"] = [(3, 3), (3, 3)]\n",
    "\n",
    "# Dense\n",
    "parameters[\"Dense_units\"] = [2000, 1000, 500]\n",
    "parameters[\"Dense_constraint\"] = None\n",
    "\n",
    "# Dropout\n",
    "parameters[\"rate\"] = [0.25, 0.25, 0.25]\n",
    "\n",
    "# SpatialDropout\n",
    "parameters[\"spatial_rate\"] = [0.15, 0.15, 0.15]\n",
    "\n",
    "# General\n",
    "parameters[\"lr\"] = 0.01\n",
    "parameters[\"epochs\"] = 100\n",
    "parameters[\"batch_size\"] = 50\n",
    "\n",
    "model = training(X, y, X_val, y_val, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrZpuwjt_wgO"
   },
   "source": [
    "### 5.2 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 963123,
     "status": "ok",
     "timestamp": 1606585980585,
     "user": {
      "displayName": "Andreas Schmitt",
      "photoUrl": "",
      "userId": "08919543814682882005"
     },
     "user_tz": -60
    },
    "id": "m52fBNNE_wgO"
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLe0DlR8_wgO"
   },
   "source": [
    "### 5.3 Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 963679,
     "status": "ok",
     "timestamp": 1606585981144,
     "user": {
      "displayName": "Andreas Schmitt",
      "photoUrl": "",
      "userId": "08919543814682882005"
     },
     "user_tz": -60
    },
    "id": "5lNB5v6G_wgP",
    "outputId": "9297fcba-537b-4e78-9736-5301f9ab6160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "model.save(WD + '/Submission/' + str(VERSION) + '/model.h5')\n",
    "\n",
    "output = pd.DataFrame(prediction, index=sample_submission_index, columns=sample_submission_columns[1:])\n",
    "output['fn'] = sample_submission_fn\n",
    "output = output[sample_submission_columns]\n",
    "\n",
    "output.to_csv(WD + '/Submission/' + str(VERSION) + '/submission.csv', index=False)\n",
    "\n",
    "print(\"Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 975144,
     "status": "ok",
     "timestamp": 1606585992612,
     "user": {
      "displayName": "Andreas Schmitt",
      "photoUrl": "",
      "userId": "08919543814682882005"
     },
     "user_tz": -60
    },
    "id": "wdfE4K5C_wgP",
    "outputId": "bfa26c5a-e754-446c-a3b9-82b7f6b7fa65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything done.\n",
      "Duration of the notebook was 972.79 seconds.\n"
     ]
    }
   ],
   "source": [
    "drive.flush_and_unmount()\n",
    "end_time = time.time()\n",
    "print(\"Everything done.\\nDuration of the notebook was {:.2f} seconds.\".format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GIZNLP_Modelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
